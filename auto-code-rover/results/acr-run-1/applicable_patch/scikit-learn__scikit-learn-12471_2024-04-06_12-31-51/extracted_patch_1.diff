diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py
index 1e05aba59..faa7a77a9 100644
--- a/sklearn/preprocessing/_encoders.py
+++ b/sklearn/preprocessing/_encoders.py
@@ -45,10 +45,8 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):
 
         """
         X_temp = check_array(X, dtype=None)
-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
-            X = check_array(X, dtype=np.object)
-        else:
-            X = X_temp
+        # Ensure that the input is always treated as an object to safely handle varying string lengths
+        X = check_array(X, dtype=np.object)
 
         if X.dtype == np.dtype('object'):
             if not _get_config()['assume_finite']:
@@ -564,12 +562,15 @@ class OneHotEncoder(_BaseEncoder):
 
         X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
 
+        # Adjust handling of unknown categories to prevent errors due to string length mismatches
+        # Instead of attempting to fit unknown strings into a fixed-size array, we now ignore them safely
         mask = X_mask.ravel()
         n_values = [cats.shape[0] for cats in self.categories_]
         n_values = np.array([0] + n_values)
         feature_indices = np.cumsum(n_values)
 
-        indices = (X_int + feature_indices[:-1]).ravel()[mask]
+        # Safely handle unknown categories by only using known categories for index calculation
+        indices = np.array([idx if mask[i] else 0 for i, idx in enumerate((X_int + feature_indices[:-1]).ravel())])
         indptr = X_mask.sum(axis=1).cumsum()
         indptr = np.insert(indptr, 0, 0)
         data = np.ones(n_samples * n_features)[mask]
