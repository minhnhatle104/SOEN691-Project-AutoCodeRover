[
    {
        "role": "system",
        "content": "You are a software developer maintaining a large project.\nYou are working on an issue submitted to your project.\nThe issue contains a description marked between <issue> and </issue>.\nYour task is to invoke a few search API calls to gather buggy information, then write patches to solve the issues.\n"
    },
    {
        "role": "user",
        "content": "<issue>Return values of non converged affinity propagation clustering\nThe affinity propagation Documentation states:\n\"When the algorithm does not converge, it returns an empty array as cluster_center_indices and -1 as label for each training sample.\"\nExample:\n```python\nfrom sklearn.cluster import AffinityPropagation\nimport pandas as pd\ndata = pd.DataFrame([[1,0,0,0,0,0],[0,1,1,1,0,0],[0,0,1,0,0,1]])\naf = AffinityPropagation(affinity='euclidean', verbose=True, copy=False, max_iter=2).fit(data)\nprint(af.cluster_centers_indices_)\nprint(af.labels_)\n```\nI would expect that the clustering here (which does not converge) prints first an empty List and then [-1,-1,-1], however, I get [2] as cluster center and [0,0,0] as cluster labels.\nThe only way I currently know if the clustering fails is if I use the verbose option, however that is very unhandy. A hacky solution is to check if max_iter == n_iter_ but it could have converged exactly 15 iterations before max_iter (although unlikely).\nI am not sure if this is intended behavior and the documentation is wrong?\nFor my use-case within a bigger script, I would prefer to get back -1 values or have a property to check if it has converged, as otherwise, a user might not be aware that the clustering never converged.\n#### Versions\nSystem:\npython: 3.6.7 | packaged by conda-forge | (default, Nov 21 2018, 02:32:25)  [GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\nexecutable: /home/jenniferh/Programs/anaconda3/envs/TF_RDKit_1_19/bin/python\nmachine: Linux-4.15.0-52-generic-x86_64-with-debian-stretch-sid\nBLAS:\nmacros: SCIPY_MKL_H=None, HAVE_CBLAS=None\nlib_dirs: /home/jenniferh/Programs/anaconda3/envs/TF_RDKit_1_19/lib\ncblas_libs: mkl_rt, pthread\nPython deps:\npip: 18.1\nsetuptools: 40.6.3\nsklearn: 0.20.3\nnumpy: 1.15.4\nscipy: 1.2.0\nCython: 0.29.2\npandas: 0.23.4\n</issue>"
    },
    {
        "role": "user",
        "content": "An external analysis tool has been deployed to identify the suspicious code to be fixed. You can choose to use the results from this tool, if you think they are useful.The tool output is as follows:\nLocalization could not produce any output."
    },
    {
        "role": "user",
        "content": "Based on the files, classes, methods, code statements from the issue that related to the bug, you can use below search APIs to get more context of the project.\n        search_class(class_name: str): Search for a class in the codebase.\n        search_method_in_file(method_name: str, file_path: str): Search for a method in a given file.\n        search_method_in_class(method_name: str, class_name: str): Search for a method in a given class.\n        search_method(method_name: str): Search for a method in the entire codebase.\n        search_code(code_str: str): Search for a code snippet in the entire codebase.\n        search_code_in_file(code_str: str, file_path: str): Search for a code snippet in a given file file.\n        Note that you can use multiple search APIs in one round.\n        Now analyze the issue and select necessary APIs to get more context of the project, each API call must have concrete arguments as inputs.\n        "
    },
    {
        "role": "assistant",
        "content": "To address the issue described, we need to understand how the `AffinityPropagation` class handles convergence and what mechanisms it uses to determine and report whether it has converged or not. Specifically, we need to look into how `cluster_centers_indices_` and `labels_` are set upon non-convergence. Additionally, checking if there's a property or method that indicates the convergence status could be useful. \n\nGiven this, I will perform the following API calls:\n\n1. `search_class(\"AffinityPropagation\")`: This will help us find the class definition and understand its structure, including any properties or methods related to convergence.\n2. `search_method_in_class(\"fit\", \"AffinityPropagation\")`: Since the issue occurs during the execution of the `fit` method, examining its implementation will provide insights into how convergence is checked and how the results are set.\n3. `search_method_in_class(\"predict\", \"AffinityPropagation\")`: To understand how labels are assigned, especially in cases of non-convergence.\n4. `search_code(\"cluster_centers_indices_\")`: This will help us find all occurrences of how `cluster_centers_indices_` is being set or used, which might give clues on its behavior upon non-convergence.\n5. `search_code(\"labels_\")`: Similar to `cluster_centers_indices_`, this will help us understand how `labels_` are handled throughout the class."
    },
    {
        "role": "user",
        "content": "Result of search_class(\"AffinityPropagation\"):\nFound 1 classes with name AffinityPropagation in the codebase.\nSearch result 1: <file>sklearn/cluster/_affinity_propagation.py</file> <class>AffinityPropagation</class> <code>class AffinityPropagation(ClusterMixin, BaseEstimator):\n    def __init__(self, damping=.5, max_iter=200, convergence_iter=15,\n                 copy=True, preference=None, affinity='euclidean',\n                 verbose=False):\n\n    @property\n    def _pairwise(self):\n    def fit(self, X, y=None):\n    def predict(self, X):\n    def fit_predict(self, X, y=None):\n</code>\n\n\n\nResult of search_method_in_class(\"fit\", \"AffinityPropagation\"):\nFound 1 methods with name fit in class AffinityPropagation.\nSearch result 1: <file>sklearn/cluster/_affinity_propagation.py</file> <class>AffinityPropagation</class> <func>fit</func> <code>    def fit(self, X, y=None):\n        \"\"\"Fit the clustering from features, or affinity matrix.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features), or \\\n            array-like, shape (n_samples, n_samples)\n            Training instances to cluster, or similarities / affinities between\n            instances if ``affinity='precomputed'``. If a sparse feature matrix\n            is provided, it will be converted into a sparse ``csr_matrix``.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        self\n\n        \"\"\"\n        if self.affinity == \"precomputed\":\n            accept_sparse = False\n        else:\n            accept_sparse = 'csr'\n        X = check_array(X, accept_sparse=accept_sparse)\n        if self.affinity == \"precomputed\":\n            self.affinity_matrix_ = X\n        elif self.affinity == \"euclidean\":\n            self.affinity_matrix_ = -euclidean_distances(X, squared=True)\n        else:\n            raise ValueError(\"Affinity must be 'precomputed' or \"\n                             \"'euclidean'. Got %s instead\"\n                             % str(self.affinity))\n\n        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n            affinity_propagation(\n                self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                convergence_iter=self.convergence_iter, damping=self.damping,\n                copy=self.copy, verbose=self.verbose, return_n_iter=True)\n\n        if self.affinity != \"precomputed\":\n            self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n\n        return self\n</code>\n\nOther results are in these files:\n\n\nResult of search_method_in_class(\"predict\", \"AffinityPropagation\"):\nFound 1 methods with name predict in class AffinityPropagation.\nSearch result 1: <file>sklearn/cluster/_affinity_propagation.py</file> <class>AffinityPropagation</class> <func>predict</func> <code>    def predict(self, X):\n        \"\"\"Predict the closest cluster each sample in X belongs to.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features)\n            New data to predict. If a sparse matrix is provided, it will be\n            converted into a sparse ``csr_matrix``.\n\n        Returns\n        -------\n        labels : ndarray, shape (n_samples,)\n            Cluster labels.\n        \"\"\"\n        check_is_fitted(self)\n        if not hasattr(self, \"cluster_centers_\"):\n            raise ValueError(\"Predict method is not supported when \"\n                             \"affinity='precomputed'.\")\n\n        if self.cluster_centers_.shape[0] > 0:\n            return pairwise_distances_argmin(X, self.cluster_centers_)\n        else:\n            warnings.warn(\"This model does not have any cluster centers \"\n                          \"because affinity propagation did not converge. \"\n                          \"Labeling every sample as '-1'.\", ConvergenceWarning)\n            return np.array([-1] * X.shape[0])\n</code>\n\nOther results are in these files:\n\n\nResult of search_code(\"cluster_centers_indices_\"):\nFound 5 snippets containing `cluster_centers_indices_` in the codebase.\nThey appeared in the following files:\n<file>examples/cluster/plot_affinity_propagation.py</file> (1 matches)\n<file>sklearn/cluster/_affinity_propagation.py</file> (3 matches)\n<file>sklearn/cluster/tests/test_affinity_propagation.py</file> (1 matches)\n\n\nResult of search_code(\"labels_\"):\nFound 604 snippets containing `labels_` in the codebase.\nThey appeared in the following files:\n<file>benchmarks/plot_tsne_mnist.py</file> (1 matches)\n<file>examples/cluster/plot_agglomerative_clustering.py</file> (1 matches)\n<file>examples/cluster/plot_color_quantization.py</file> (2 matches)\n<file>examples/cluster/plot_digits_agglomeration.py</file> (1 matches)\n<file>examples/cluster/plot_adjusted_for_chance_measures.py</file> (5 matches)\n<file>examples/cluster/plot_agglomerative_dendrogram.py</file> (1 matches)\n<file>examples/cluster/plot_affinity_propagation.py</file> (7 matches)\n<file>examples/cluster/plot_birch_vs_minibatchkmeans.py</file> (4 matches)\n<file>examples/cluster/plot_optics.py</file> (12 matches)\n<file>examples/cluster/plot_kmeans_stability_low_dim_dense.py</file> (1 matches)\n<file>examples/cluster/plot_digits_linkage.py</file> (1 matches)\n<file>examples/cluster/plot_mean_shift.py</file> (3 matches)\n<file>examples/cluster/plot_mini_batch_kmeans.py</file> (1 matches)\n<file>examples/cluster/plot_linkage_comparison.py</file> (2 matches)\n<file>examples/cluster/plot_face_compress.py</file> (1 matches)\n<file>examples/cluster/plot_dbscan.py</file> (8 matches)\n<file>examples/cluster/plot_cluster_iris.py</file> (1 matches)\n<file>examples/cluster/plot_kmeans_digits.py</file> (6 matches)\n<file>examples/cluster/plot_agglomerative_clustering_metrics.py</file> (1 matches)\n<file>examples/cluster/plot_cluster_comparison.py</file> (2 matches)\n<file>examples/cluster/plot_coin_ward_segmentation.py</file> (1 matches)\n<file>examples/cluster/plot_ward_structured_vs_unstructured.py</file> (2 matches)\n<file>examples/text/plot_document_clustering.py</file> (5 matches)\n<file>examples/bicluster/plot_spectral_coclustering.py</file> (2 matches)\n<file>examples/bicluster/plot_bicluster_newsgroups.py</file> (2 matches)\n<file>examples/bicluster/plot_spectral_biclustering.py</file> (4 matches)\n<file>sklearn/base.py</file> (1 matches)\n<file>sklearn/neighbors/tests/test_neighbors_pipeline.py</file> (8 matches)\n<file>sklearn/datasets/_svmlight_format.py</file> (5 matches)\n<file>sklearn/metrics/_classification.py</file> (4 matches)\n<file>sklearn/metrics/cluster/_supervised.py</file> (133 matches)\n<file>sklearn/metrics/cluster/tests/test_supervised.py</file> (74 matches)\n<file>sklearn/metrics/tests/test_common.py</file> (2 matches)\n<file>sklearn/metrics/tests/test_classification.py</file> (11 matches)\n<file>sklearn/metrics/tests/test_ranking.py</file> (1 matches)\n<file>sklearn/utils/estimator_checks.py</file> (18 matches)\n<file>sklearn/utils/tests/test_multiclass.py</file> (2 matches)\n<file>sklearn/utils/tests/test_deprecated_utils.py</file> (1 matches)\n<file>sklearn/cluster/_spectral.py</file> (3 matches)\n<file>sklearn/cluster/_mean_shift.py</file> (4 matches)\n<file>sklearn/cluster/_k_means.py</file> (29 matches)\n<file>sklearn/cluster/_affinity_propagation.py</file> (3 matches)\n<file>sklearn/cluster/_bicluster.py</file> (17 matches)\n<file>sklearn/cluster/_optics.py</file> (10 matches)\n<file>sklearn/cluster/_birch.py</file> (6 matches)\n<file>sklearn/cluster/_hierarchical.py</file> (5 matches)\n<file>sklearn/cluster/_feature_agglomeration.py</file> (6 matches)\n<file>sklearn/cluster/_dbscan.py</file> (5 matches)\n<file>sklearn/cluster/tests/test_mean_shift.py</file> (14 matches)\n<file>sklearn/cluster/tests/test_optics.py</file> (25 matches)\n<file>sklearn/cluster/tests/test_birch.py</file> (11 matches)\n<file>sklearn/cluster/tests/test_affinity_propagation.py</file> (8 matches)\n<file>sklearn/cluster/tests/test_dbscan.py</file> (31 matches)\n<file>sklearn/cluster/tests/test_feature_agglomeration.py</file> (4 matches)\n<file>sklearn/cluster/tests/test_spectral.py</file> (22 matches)\n<file>sklearn/cluster/tests/test_hierarchical.py</file> (18 matches)\n<file>sklearn/cluster/tests/test_k_means.py</file> (44 matches)\n<file>sklearn/manifold/tests/test_spectral_embedding.py</file> (1 matches)\n<file>sklearn/mixture/_base.py</file> (1 matches)\n\n\n"
    },
    {
        "role": "user",
        "content": "Let's analyze collected context first"
    },
    {
        "role": "assistant",
        "content": "Based on the collected context, here's an analysis of the issue and potential approaches to address it:\n\n1. **Issue Summary**: The user reported that the `AffinityPropagation` class does not behave as documented when it fails to converge. Specifically, instead of returning an empty array for `cluster_centers_indices_` and `-1` for each label in `labels_`, it returns unexpected values. This discrepancy between expected and actual behavior suggests either a documentation error or a bug in the implementation of the `AffinityPropagation` class.\n\n2. **Analysis of `AffinityPropagation` Class**:\n    - The `AffinityPropagation` class is defined with methods that are crucial for clustering, such as `fit`, `predict`, and `fit_predict`.\n    - The `fit` method is responsible for fitting the clustering from features or an affinity matrix. It uses the `affinity_propagation` function to compute `cluster_centers_indices_`, `labels_`, and `n_iter_`. The behavior when the algorithm does not converge needs to be scrutinized here.\n    - The `predict` method includes a warning mechanism for when the model does not have any cluster centers because the affinity propagation did not converge. This suggests that there is already some handling of non-convergence cases, specifically in the context of the `predict` method.\n\n3. **Potential Solutions**:\n    - **Review and Update Documentation**: If the current behavior (returning non-empty `cluster_centers_indices_` and non-negative `labels_`) is intended, the documentation should be updated to reflect this accurately.\n    - **Modify Convergence Behavior**: If the behavior described in the documentation is desired (i.e., returning an empty array for `cluster_centers_indices_` and `-1` for each label in `labels_` upon non-convergence), the implementation of the `fit` method in the `AffinityPropagation` class needs to be adjusted. Specifically, after the call to `affinity_propagation`, there should be a check to determine if the algorithm has indeed converged. This could be based on whether `n_iter_` has reached `max_iter` without meeting the convergence criteria.\n        - A possible patch could involve adding a condition after the `affinity_propagation` call in the `fit` method to check for non-convergence and adjust `cluster_centers_indices_` and `labels_` accordingly.\n    - **Enhance Convergence Detection**: Introduce a more explicit property or method to indicate whether the algorithm has converged. This could be a boolean flag set during the execution of `affinity_propagation` that users can easily check.\n\n4. **Next Steps**:\n    - Decide on the desired behavior (as documented or as currently implemented).\n    - Implement the necessary changes either in the code (to match the documentation) or in the documentation (to match the code's behavior).\n    - Consider adding more explicit handling or reporting of convergence status to improve user experience and clarity.\n\nGiven this analysis, the next step would involve either drafting a patch to adjust the behavior of the `AffinityPropagation` class to match the documentation or updating the documentation to reflect the actual behavior, depending on the decision regarding the desired behavior."
    },
    {
        "role": "user",
        "content": "Based on your analysis, answer below questions:  - do we need more context: construct search API calls to get more context of the project. (leave it empty if you don't need more context)  - where are bug locations: buggy files and methods. (leave it empty if you don't have enough information)"
    },
    {
        "role": "assistant",
        "content": "- **Do we need more context**: \n\nGiven the information provided and the analysis conducted, we have sufficient context to proceed with addressing the issue. The key components of the `AffinityPropagation` class, including its `fit` and `predict` methods, have been examined. Additionally, the behavior of `cluster_centers_indices_` and `labels_` in non-convergence scenarios has been identified as the core of the issue. Therefore, no further context from the project is needed at this moment.\n\n- **Where are bug locations**:\n\nBuggy File: `sklearn/cluster/_affinity_propagation.py`\n\nBuggy Methods:\n1. `fit`: This method needs to be reviewed and potentially modified to ensure that it behaves as documented when the algorithm does not converge. Specifically, it should return an empty array for `cluster_centers_indices_` and `-1` for each label in `labels_` in case of non-convergence.\n2. Documentation or Comments: Depending on the decision (whether to change the code to match the documentation or update the documentation to reflect the current behavior), the documentation/comments within the `AffinityPropagation` class or its methods may also need to be updated to accurately describe the behavior in non-convergence scenarios."
    },
    {
        "role": "user",
        "content": "Here are the code in buggy locations:\nFound 1 methods with name fit in class AffinityPropagation.\nSearch result 1: <file>sklearn/cluster/_affinity_propagation.py</file> <class>AffinityPropagation</class> <func>fit</func> <code>    def fit(self, X, y=None):\n        \"\"\"Fit the clustering from features, or affinity matrix.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features), or \\\n            array-like, shape (n_samples, n_samples)\n            Training instances to cluster, or similarities / affinities between\n            instances if ``affinity='precomputed'``. If a sparse feature matrix\n            is provided, it will be converted into a sparse ``csr_matrix``.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        self\n\n        \"\"\"\n        if self.affinity == \"precomputed\":\n            accept_sparse = False\n        else:\n            accept_sparse = 'csr'\n        X = check_array(X, accept_sparse=accept_sparse)\n        if self.affinity == \"precomputed\":\n            self.affinity_matrix_ = X\n        elif self.affinity == \"euclidean\":\n            self.affinity_matrix_ = -euclidean_distances(X, squared=True)\n        else:\n            raise ValueError(\"Affinity must be 'precomputed' or \"\n                             \"'euclidean'. Got %s instead\"\n                             % str(self.affinity))\n\n        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n            affinity_propagation(\n                self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                convergence_iter=self.convergence_iter, damping=self.damping,\n                copy=self.copy, verbose=self.verbose, return_n_iter=True)\n\n        if self.affinity != \"precomputed\":\n            self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n\n        return self\n</code>\n\nOther results are in these files:\n\nFound 1 classes with name AffinityPropagation in file sklearn/cluster/_affinity_propagation.py.\nSearch result 1: <file>sklearn/cluster/_affinity_propagation.py</file> <class>AffinityPropagation</class> <code>class AffinityPropagation(ClusterMixin, BaseEstimator):\n    \"\"\"Perform Affinity Propagation Clustering of data.\n\n    Read more in the :ref:`User Guide <affinity_propagation>`.\n\n    Parameters\n    ----------\n    damping : float, optional, default: 0.5\n        Damping factor (between 0.5 and 1) is the extent to\n        which the current value is maintained relative to\n        incoming values (weighted 1 - damping). This in order\n        to avoid numerical oscillations when updating these\n        values (messages).\n\n    max_iter : int, optional, default: 200\n        Maximum number of iterations.\n\n    convergence_iter : int, optional, default: 15\n        Number of iterations with no change in the number\n        of estimated clusters that stops the convergence.\n\n    copy : boolean, optional, default: True\n        Make a copy of input data.\n\n    preference : array-like, shape (n_samples,) or float, optional\n        Preferences for each point - points with larger values of\n        preferences are more likely to be chosen as exemplars. The number\n        of exemplars, ie of clusters, is influenced by the input\n        preferences value. If the preferences are not passed as arguments,\n        they will be set to the median of the input similarities.\n\n    affinity : string, optional, default=``euclidean``\n        Which affinity to use. At the moment ``precomputed`` and\n        ``euclidean`` are supported. ``euclidean`` uses the\n        negative squared euclidean distance between points.\n\n    verbose : boolean, optional, default: False\n        Whether to be verbose.\n\n\n    Attributes\n    ----------\n    cluster_centers_indices_ : array, shape (n_clusters,)\n        Indices of cluster centers\n\n    cluster_centers_ : array, shape (n_clusters, n_features)\n        Cluster centers (if affinity != ``precomputed``).\n\n    labels_ : array, shape (n_samples,)\n        Labels of each point\n\n    affinity_matrix_ : array, shape (n_samples, n_samples)\n        Stores the affinity matrix used in ``fit``.\n\n    n_iter_ : int\n        Number of iterations taken to converge.\n\n    Examples\n    --------\n    >>> from sklearn.cluster import AffinityPropagation\n    >>> import numpy as np\n    >>> X = np.array([[1, 2], [1, 4], [1, 0],\n    ...               [4, 2], [4, 4], [4, 0]])\n    >>> clustering = AffinityPropagation().fit(X)\n    >>> clustering\n    AffinityPropagation()\n    >>> clustering.labels_\n    array([0, 0, 0, 1, 1, 1])\n    >>> clustering.predict([[0, 0], [4, 4]])\n    array([0, 1])\n    >>> clustering.cluster_centers_\n    array([[1, 2],\n           [4, 2]])\n\n    Notes\n    -----\n    For an example, see :ref:`examples/cluster/plot_affinity_propagation.py\n    <sphx_glr_auto_examples_cluster_plot_affinity_propagation.py>`.\n\n    The algorithmic complexity of affinity propagation is quadratic\n    in the number of points.\n\n    When ``fit`` does not converge, ``cluster_centers_`` becomes an empty\n    array and all training samples will be labelled as ``-1``. In addition,\n    ``predict`` will then label every sample as ``-1``.\n\n    When all training samples have equal similarities and equal preferences,\n    the assignment of cluster centers and labels depends on the preference.\n    If the preference is smaller than the similarities, ``fit`` will result in\n    a single cluster center and label ``0`` for every sample. Otherwise, every\n    training sample becomes its own cluster center and is assigned a unique\n    label.\n\n    References\n    ----------\n\n    Brendan J. Frey and Delbert Dueck, \"Clustering by Passing Messages\n    Between Data Points\", Science Feb. 2007\n    \"\"\"\n\n    def __init__(self, damping=.5, max_iter=200, convergence_iter=15,\n                 copy=True, preference=None, affinity='euclidean',\n                 verbose=False):\n\n        self.damping = damping\n        self.max_iter = max_iter\n        self.convergence_iter = convergence_iter\n        self.copy = copy\n        self.verbose = verbose\n        self.preference = preference\n        self.affinity = affinity\n\n    @property\n    def _pairwise(self):\n        return self.affinity == \"precomputed\"\n\n    def fit(self, X, y=None):\n        \"\"\"Fit the clustering from features, or affinity matrix.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features), or \\\n            array-like, shape (n_samples, n_samples)\n            Training instances to cluster, or similarities / affinities between\n            instances if ``affinity='precomputed'``. If a sparse feature matrix\n            is provided, it will be converted into a sparse ``csr_matrix``.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        self\n\n        \"\"\"\n        if self.affinity == \"precomputed\":\n            accept_sparse = False\n        else:\n            accept_sparse = 'csr'\n        X = check_array(X, accept_sparse=accept_sparse)\n        if self.affinity == \"precomputed\":\n            self.affinity_matrix_ = X\n        elif self.affinity == \"euclidean\":\n            self.affinity_matrix_ = -euclidean_distances(X, squared=True)\n        else:\n            raise ValueError(\"Affinity must be 'precomputed' or \"\n                             \"'euclidean'. Got %s instead\"\n                             % str(self.affinity))\n\n        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n            affinity_propagation(\n                self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                convergence_iter=self.convergence_iter, damping=self.damping,\n                copy=self.copy, verbose=self.verbose, return_n_iter=True)\n\n        if self.affinity != \"precomputed\":\n            self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n\n        return self\n\n    def predict(self, X):\n        \"\"\"Predict the closest cluster each sample in X belongs to.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features)\n            New data to predict. If a sparse matrix is provided, it will be\n            converted into a sparse ``csr_matrix``.\n\n        Returns\n        -------\n        labels : ndarray, shape (n_samples,)\n            Cluster labels.\n        \"\"\"\n        check_is_fitted(self)\n        if not hasattr(self, \"cluster_centers_\"):\n            raise ValueError(\"Predict method is not supported when \"\n                             \"affinity='precomputed'.\")\n\n        if self.cluster_centers_.shape[0] > 0:\n            return pairwise_distances_argmin(X, self.cluster_centers_)\n        else:\n            warnings.warn(\"This model does not have any cluster centers \"\n                          \"because affinity propagation did not converge. \"\n                          \"Labeling every sample as '-1'.\", ConvergenceWarning)\n            return np.array([-1] * X.shape[0])\n\n    def fit_predict(self, X, y=None):\n        \"\"\"Fit the clustering from features or affinity matrix, and return\n        cluster labels.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features), or \\\n            array-like, shape (n_samples, n_samples)\n            Training instances to cluster, or similarities / affinities between\n            instances if ``affinity='precomputed'``. If a sparse feature matrix\n            is provided, it will be converted into a sparse ``csr_matrix``.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        labels : ndarray, shape (n_samples,)\n            Cluster labels.\n        \"\"\"\n        return super().fit_predict(X, y)\n</code>\n\n\n"
    }
]